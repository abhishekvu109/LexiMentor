spring:
  ai:
    ollama:
      base-url: http://${LLAMA_HOST:localhost}:${LLAMA_PORT:11434}
      chat:
        model: llama3
server:
  port: 6565
