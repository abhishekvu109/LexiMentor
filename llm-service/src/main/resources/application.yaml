spring:
  ai:
    ollama:
      base-url: http://${LLAMA_HOST:localhost}:${LLAMA_PORT:11434}
      chat:
        model: deepseek-r1:1.5b
server:
  port: 6565
